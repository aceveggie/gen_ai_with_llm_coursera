# gen_ai_with_llm_coursera


## Syllabus:

1. Week 1: 
    * Introduction to LLMs and the generative AI project lifecycle:
        1. Prompt
        2. LLM
        3. Context Window.
        4. Complettion
        5. Inference
        6. Issues with Tradtional Text Generation (with LSTMs).
        7. Transformers
        8. Tokenizers
        9. Embedding Layers, Positional Embedding.
        10. Generating text with Transformers.
        11. Encoder Decoder models (BART, T5, etc.), Encoder only models (BERT, etc.), Decoder only models (GPT, LLAMA).
        12. Prompting, Prompt Engineering (In context learning, zero-shot inference, 1-shot inference, few shot inference).
        13. Generative Configuration (Max new tokens, Temperature, Greedy/Random sampling, Top-P, Top-K sampling).
        14. Gen AI Project Life Cycle.

    * LLM pre-training and scaling laws:
        1. Encoder only models, use cases, examples.
        2. Decoder only models, use cases, examples.
        3. Encoder Decoder models, use cases, examples.
        4. Computational challenges of training LLMs.
        5. Scaling laws and compute optimal models (Chinchilla).
        6. Pre-training for domain adaptation
    
    * Quiz covering above 
    * Programming assignment on SageMaker:
        0. T5 model inference (for dialogue summarization).
        1. zero shot prompting.
        2. 1 shot prompting.
        3. Few shot prompting.
        
        